{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e44c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ClusterDataset import ClusterDataset as GNNDataset\n",
    "from ClusterDatasetTransformer import ClusterDataset\n",
    "from train_transformer import *\n",
    "from data_statistics import *\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from Transformer import Transformer\n",
    "from lang import Lang\n",
    "from LossFunction import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce07a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779bf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 60\n",
    "max_seq_length = 60\n",
    "batch_size = 8\n",
    "converter = Lang(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfda33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05055d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "hist_folder = \"/eos/user/c/czeh/histo_10pion0PU/\"\n",
    "data_folder_training = \"/eos/user/c/czeh/graph_data/processed\"\n",
    "store_folder_training = \"/eos/user/c/czeh/graph_data_trans\"\n",
    "data_folder_test = \"/eos/user/c/czeh/graph_data_test/processed\"\n",
    "store_folder_test = \"/eos/user/c/czeh/graph_data_trans_test\"\n",
    "\n",
    "dataset_training = ClusterDataset(store_folder_training, data_folder_training, input_length=input_length, output_group=True)\n",
    "dataset_test = ClusterDataset(store_folder_test, data_folder_test, input_length=input_length, output_group=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset_training, shuffle=True, batch_size=batch_size, pin_memory=True, num_workers=4)\n",
    "test_dl = DataLoader(dataset_test, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3aff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 6\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "padding = converter.word2index[\"<PAD>\"]\n",
    "feature_num = len(dataset_test.model_feature_keys)\n",
    "max_nodes = max(dataset_test.max_nodes, dataset_test.max_nodes)\n",
    "vocab_size = max_nodes + 4\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "criterion = Loss(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5476f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally introduce weight decay\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Drop Step Size over time\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Weights if needed\n",
    "# weights = torch.load(\"/eos/user/c/czeh/tranformer_2.pt\", weights_only=True)\n",
    "# model.load_state_dict(weights[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(weights[\"optimizer_state_dict\"])\n",
    "# start_epoch = weights[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_hist = []\n",
    "val_loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee1a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\n",
    "# Optionally introduce gradient clipping\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.25)\n",
    "\n",
    "fig_loss, ax_loss = plt.subplots(1, 1)\n",
    "fig_loss.set_figwidth(6)\n",
    "fig_loss.set_figheight(3)\n",
    "\n",
    "display_loss = display(1, display_id=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 101):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    \n",
    "    loss = train(model, optimizer, test_dl, epoch, criterion, vocab_size, device=device)\n",
    "    print(f\"Training loss: {loss}\")\n",
    "    train_loss_hist.append(loss)\n",
    "    \n",
    "    val_loss = test(model, test_dl, epoch, criterion, vocab_size, device=device)\n",
    "    val_loss_hist.append(val_loss)\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    \n",
    "    ax_loss.clear()\n",
    "    plot_loss(train_loss_hist, val_loss_hist, ax=ax_loss, n=1)\n",
    "    display_loss.update(fig_loss)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, LR: {scheduler.get_last_lr()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "epochs = len(train_loss_hist)\n",
    "ax.plot(range(1, epochs+1), moving_average(train_loss_hist, 8), label='train', linewidth=2)\n",
    "ax.plot(range(1, epochs+1), moving_average(val_loss_hist, 8), label='val', linewidth=2)\n",
    "ax.set_ylabel(\"Loss\", fontsize=14)\n",
    "ax.set_xlabel(\"Epochs\", fontsize=14)\n",
    "ax.set_title(\"Training and Validation Loss\", fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ba369",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = f\"{datetime.now():%Y-%m-%d}\"\n",
    "save_model(model, epoch, optimizer, train_loss_hist, val_loss_hist, model_folder, f\"tranformer_date_{date}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d246b",
   "metadata": {},
   "source": [
    "## Test Full Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EventGrouping import EventGrouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d461c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "weights = torch.load(\"/eos/user/c/czeh/tranformer_4.pt\", weights_only=True)\n",
    "model2.load_state_dict(weights[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = EventGrouping(converter, model2, neighborhood=1, seq_length=input_length)\n",
    "runner(dataset_test.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea085d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature_keys = np.array([0,  2,  3,  4,  6,  7, 10, 14, 15, 16, 17, 18, 22, 24, 25, 26, 28, 29])\n",
    "dataset_training.__getitem__(0)[0][:, model_feature_keys][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1207fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.get(0).cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.node_feature_keys[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch_geometric.utils.to_networkx(dataset_test.get(0), to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5878291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.get(0).x[:, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "nx.draw(G, with_labels=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661d336",
   "metadata": {},
   "source": [
    "## Random Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = dataset_training.__getitem__(0)[2]\n",
    "mask = targets != -4\n",
    "mask.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[targets[:, -1] != -4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[mask].shape[0]/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = dataset_training.__getitem__(0)[1]\n",
    "opts = torch.roll(opts, -1, dims=0)\n",
    "opts[-1] = 5\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ccda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask = opts != -4\n",
    "opts[out_mask].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c35fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.reshape(targets[mask], (int(targets[mask].shape[0]/3), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd836c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf31c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

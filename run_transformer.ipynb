{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e44c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ClusterDataset import ClusterDataset as GNNDataset\n",
    "from ClusterDatasetTransformer import ClusterDataset\n",
    "from train_transformer import *\n",
    "from data_statistics import *\n",
    "from GNN_TrackLinkingNet import EarlyStopping\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from Transformer import Transformer\n",
    "from lang import Lang\n",
    "from LossFunction import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce07a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 60\n",
    "max_seq_length = 60\n",
    "batch_size = 64\n",
    "converter = Lang(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfda33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05055d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "model_folder = \"/eos/user/c/czeh/\"\n",
    "hist_folder = \"/eos/user/c/czeh/histo_10pion0PU/\"\n",
    "data_folder_training = \"/eos/user/c/czeh/graph_data/processed\"\n",
    "store_folder_training = \"/eos/user/c/czeh/graph_data_trans\"\n",
    "data_folder_test = \"/eos/user/c/czeh/graph_data_test/processed\"\n",
    "store_folder_test = \"/eos/user/c/czeh/graph_data_trans_test\"\n",
    "\n",
    "dataset_training = ClusterDataset(store_folder_training, data_folder_training, input_length=input_length, output_group=False)\n",
    "dataset_test = ClusterDataset(store_folder_test, data_folder_test, input_length=input_length, output_group=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset_training, shuffle=True, batch_size=batch_size)\n",
    "test_dl = DataLoader(dataset_test, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3aff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 6\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "padding = converter.word2index[\"<PAD>\"]\n",
    "feature_num = len(dataset_test.model_feature_keys)\n",
    "max_nodes = max(dataset_test.max_nodes, dataset_test.max_nodes)\n",
    "vocab_size = max_nodes + 4\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "criterion = Loss(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5476f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally introduce weight decay\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Drop Step Size over time\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "early_stopping = EarlyStopping(patience=5, delta=-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Weights if needed\n",
    "# weights = torch.load(\"/eos/user/c/czeh/tranformer_2.pt\", weights_only=True)\n",
    "# model.load_state_dict(weights[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(weights[\"optimizer_state_dict\"])\n",
    "# start_epoch = weights[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_hist = []\n",
    "val_loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee1a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\n",
    "# Optionally introduce gradient clipping\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.25)\n",
    "\n",
    "fig_loss, ax_loss = plt.subplots(1, 1)\n",
    "fig_loss.set_figwidth(6)\n",
    "fig_loss.set_figheight(3)\n",
    "\n",
    "display_loss = display(1, display_id=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 101):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    \n",
    "    loss = train(model, optimizer, train_dl, epoch, criterion, vocab_size, device=device)\n",
    "    print(f\"Training loss: {loss}\")\n",
    "    train_loss_hist.append(loss)\n",
    "    \n",
    "    val_loss = test(model, test_dl, epoch, criterion, vocab_size, device=device)\n",
    "    val_loss_hist.append(val_loss)\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    \n",
    "    ax_loss.clear()\n",
    "    plot_loss(train_loss_hist, val_loss_hist, ax=ax_loss, n=1)\n",
    "    display_loss.update(fig_loss)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "    \n",
    "    early_stopping(model, val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping after {epoch+1} epochs\")\n",
    "        early_stopping.load_best_model(model)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "epochs = len(train_loss_hist)\n",
    "ax.plot(range(1, epochs+1), moving_average(train_loss_hist, 8), label='train', linewidth=2)\n",
    "ax.plot(range(1, epochs+1), moving_average(val_loss_hist, 8), label='val', linewidth=2)\n",
    "ax.set_ylabel(\"Loss\", fontsize=14)\n",
    "ax.set_xlabel(\"Epochs\", fontsize=14)\n",
    "ax.set_title(\"Training and Validation Loss\", fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ba369",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = f\"{datetime.now():%Y-%m-%d}\"\n",
    "save_model(model, epoch, optimizer, train_loss_hist, val_loss_hist, model_folder, f\"tranformer_date_{date}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d246b",
   "metadata": {},
   "source": [
    "## Test Full Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0820217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EventGrouping import EventGrouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d461c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "weights = torch.load(\"/eos/user/c/czeh/tranformer_date_2025-05-30.pt\", weights_only=True)\n",
    "model.load_state_dict(weights[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63169563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "components = dataset_test.get(0)\n",
    "print(len(components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6713f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 10,  8,  6,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5, 17,  4, 18, 16, 14,  4, 18, 16, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3], device='cuda:0')\n",
      "[114 118 120 125 127 134 145 152 160]\n",
      "0\n",
      "tensor([1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "[116]\n",
      "1\n",
      "tensor([ 1,  9,  3, 16,  3, 16, 14,  3, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13], device='cuda:0')\n",
      "[170 194 202 204]\n",
      "5\n",
      "tensor([ 1,  4,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11], device='cuda:0')\n",
      "[123 162]\n",
      "16\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8], device='cuda:0')\n",
      "[131 133 157]\n",
      "17\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0], device='cuda:0')\n",
      "[136 153]\n",
      "18\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 4, 3, 3, 3, 3, 0], device='cuda:0')\n",
      "[154]\n",
      "19\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 4, 3, 3, 3, 3, 3, 0], device='cuda:0')\n",
      "[161]\n",
      "20\n",
      "tensor([1, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 7, 0, 7, 0, 7, 0, 7, 0], device='cuda:0')\n",
      "[174 185 195]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "runner = EventGrouping(model, seq_length=input_length)\n",
    "\n",
    "\n",
    "nTrackster = 0\n",
    "for component in components:\n",
    "    max_comp_t = int(torch.max(component[\"x\"]).item())\n",
    "    if max_comp_t > nTrackster:\n",
    "        nTrackster = max_comp_t\n",
    "  \n",
    "group = 0\n",
    "edges = np.full(nTrackster, -1)\n",
    "\n",
    "    \n",
    "for component in components:\n",
    "    res = runner(component)[-1]\n",
    "    print(res)\n",
    "    converter = Lang(trackster_list=component[\"lang\"])\n",
    "    new_groups = converter.seq2y(res.cpu().numpy(), nodes=nTrackster, start_group=group)\n",
    "    print(np.array(range(new_groups.shape[0]))[new_groups >= 0])\n",
    "    edges = np.maximum(edges, converter.seq2y(res.cpu().numpy(), nodes=nTrackster, start_group=group))\n",
    "    print(np.max(edges))\n",
    "    group = np.max(edges) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f43dec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  0,  0,  6,  0,  0, 17, 17,  0, 18,  0,  0, 18, 19, 17,  0,\n",
       "       20, 16,  2, 21, 21,  5, 46,  4,  4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges[edges>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea085d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature_keys = np.array([0,  2,  3,  4,  6,  7, 10, 14, 15, 16, 17, 18, 22, 24, 25, 26, 28, 29])\n",
    "dataset_training.__getitem__(0)[0][:, model_feature_keys][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1207fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.get(0).cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.node_feature_keys[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch_geometric.utils.to_networkx(dataset_test.get(0), to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5878291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.get(0).x[:, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "nx.draw(G, with_labels=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661d336",
   "metadata": {},
   "source": [
    "## Random Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c40f6ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "weights = torch.load(\"/eos/user/c/czeh/tranformer_date_2025-05-30.pt\", weights_only=True)\n",
    "model.load_state_dict(weights[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336209ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114, 118, 125, 126, 127, 132, 134, 144, 149, 151, 152, 121, 145,\n",
       "       160, 120, 117, 191, 139, 142, 146])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = dataset_test.get(0)\n",
    "components[0][\"lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6906b444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bde713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  1, 10], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = components[0][\"nTrackster\"]\n",
    "converter = Lang(trackster_list=components[0][\"lang\"])\n",
    "sample_seq = converter.starting_seq(components[0][\"root\"], input_length).to(device)\n",
    "print(sample_seq)\n",
    "\n",
    "X = components[0][\"x\"].float()\n",
    "X = F.pad(X, pad=(0, 0, max_nodes - num_nodes, 0), value=converter.word2index[\"<PAD>\"])\n",
    "X = X[:, list(map(dataset_test.node_feature_dict.get, dataset_test.model_feature_keys))]\n",
    "\n",
    "predictions = model(torch.unsqueeze(X, dim=0), torch.unsqueeze(sample_seq, dim=0))\n",
    "torch.argsort(predictions[0, -1, :num_nodes], dim=0)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[targets[:, -1] != -4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[mask].shape[0]/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = dataset_training.__getitem__(0)[1]\n",
    "opts = torch.roll(opts, -1, dims=0)\n",
    "opts[-1] = 5\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ccda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask = opts != -4\n",
    "opts[out_mask].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c35fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.reshape(targets[mask], (int(targets[mask].shape[0]/3), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd836c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf31c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e44c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:48:10.306183: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-30 14:48:10.327116: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748609290.351747    2033 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748609290.359268    2033 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-30 14:48:10.385905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ClusterDataset import ClusterDataset as GNNDataset\n",
    "from ClusterDatasetTransformer import ClusterDataset\n",
    "from train_transformer import *\n",
    "from data_statistics import *\n",
    "from GNN_TrackLinkingNet import EarlyStopping\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from Transformer import Transformer\n",
    "from lang import Lang\n",
    "from LossFunction import Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce07a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779bf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 60\n",
    "max_seq_length = 60\n",
    "batch_size = 64\n",
    "converter = Lang(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfda33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05055d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "model_folder = \"/eos/user/c/czeh/\"\n",
    "hist_folder = \"/eos/user/c/czeh/histo_10pion0PU/\"\n",
    "data_folder_training = \"/eos/user/c/czeh/graph_data/processed\"\n",
    "store_folder_training = \"/eos/user/c/czeh/graph_data_trans\"\n",
    "data_folder_test = \"/eos/user/c/czeh/graph_data_test/processed\"\n",
    "store_folder_test = \"/eos/user/c/czeh/graph_data_trans_test\"\n",
    "\n",
    "dataset_training = ClusterDataset(store_folder_training, data_folder_training, input_length=input_length, output_group=False)\n",
    "dataset_test = ClusterDataset(store_folder_test, data_folder_test, input_length=input_length, output_group=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4399f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset_training, shuffle=True, batch_size=batch_size)\n",
    "test_dl = DataLoader(dataset_test, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3aff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "d_model = 128\n",
    "num_heads = 4\n",
    "num_layers = 6\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "padding = converter.word2index[\"<PAD>\"]\n",
    "feature_num = len(dataset_test.model_feature_keys)\n",
    "max_nodes = max(dataset_test.max_nodes, dataset_test.max_nodes)\n",
    "vocab_size = max_nodes + 4\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "criterion = Loss(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5476f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally introduce weight decay\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# Drop Step Size over time\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "early_stopping = EarlyStopping(patience=5, delta=-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Weights if needed\n",
    "# weights = torch.load(\"/eos/user/c/czeh/tranformer_2.pt\", weights_only=True)\n",
    "# model.load_state_dict(weights[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(weights[\"optimizer_state_dict\"])\n",
    "# start_epoch = weights[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_hist = []\n",
    "val_loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee1a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\n",
    "# Optionally introduce gradient clipping\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.25)\n",
    "\n",
    "fig_loss, ax_loss = plt.subplots(1, 1)\n",
    "fig_loss.set_figwidth(6)\n",
    "fig_loss.set_figheight(3)\n",
    "\n",
    "display_loss = display(1, display_id=True)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 101):\n",
    "    print(f'Epoch: {epoch}')\n",
    "    \n",
    "    loss = train(model, optimizer, train_dl, epoch, criterion, vocab_size, device=device)\n",
    "    print(f\"Training loss: {loss}\")\n",
    "    train_loss_hist.append(loss)\n",
    "    \n",
    "    val_loss = test(model, test_dl, epoch, criterion, vocab_size, device=device)\n",
    "    val_loss_hist.append(val_loss)\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    \n",
    "    ax_loss.clear()\n",
    "    plot_loss(train_loss_hist, val_loss_hist, ax=ax_loss, n=1)\n",
    "    display_loss.update(fig_loss)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, LR: {scheduler.get_last_lr()[0]}\")\n",
    "    \n",
    "    early_stopping(model, val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping after {epoch+1} epochs\")\n",
    "        early_stopping.load_best_model(model)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(10)\n",
    "epochs = len(train_loss_hist)\n",
    "ax.plot(range(1, epochs+1), moving_average(train_loss_hist, 8), label='train', linewidth=2)\n",
    "ax.plot(range(1, epochs+1), moving_average(val_loss_hist, 8), label='val', linewidth=2)\n",
    "ax.set_ylabel(\"Loss\", fontsize=14)\n",
    "ax.set_xlabel(\"Epochs\", fontsize=14)\n",
    "ax.set_title(\"Training and Validation Loss\", fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090ba369",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = f\"{datetime.now():%Y-%m-%d}\"\n",
    "save_model(model, epoch, optimizer, train_loss_hist, val_loss_hist, model_folder, f\"tranformer_date_{date}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4d246b",
   "metadata": {},
   "source": [
    "## Test Full Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0820217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EventGrouping import EventGrouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d461c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "weights = torch.load(\"/eos/user/c/czeh/tranformer_date_2025-05-30.pt\", weights_only=True)\n",
    "model.load_state_dict(weights[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09294567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114, 118, 125, 126, 127, 132, 134, 144, 149, 151, 152, 121, 145,\n",
       "       160, 120, 117, 191, 139, 142, 146])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = dataset_test.get(0)\n",
    "components[0][\"lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6713f027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  1, 10], device='cuda:0')\n",
      "127\n",
      "127\n",
      "127\n",
      "125\n",
      "114\n",
      "114\n",
      "114\n",
      "160\n",
      "118\n",
      "160\n",
      "118\n",
      "117\n",
      "114\n",
      "160\n",
      "118\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "152\n",
      "134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  1, 10,  8], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  1, 10,  8,  8], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1, 10,  8,  8,  8], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          1, 10,  8,  8,  8,  6], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         10,  8,  8,  8,  6,  4], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,\n",
       "          8,  8,  8,  6,  4,  4], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,\n",
       "          8,  8,  6,  4,  4,  4], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,\n",
       "          8,  6,  4,  4,  4, 17], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,\n",
       "          6,  4,  4,  4, 17,  5], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,\n",
       "          4,  4,  4, 17,  5, 17], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,\n",
       "          4,  4, 17,  5, 17,  5], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,\n",
       "          4, 17,  5, 17,  5, 19], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4,\n",
       "         17,  5, 17,  5, 19,  4], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4, 17,\n",
       "          5, 17,  5, 19,  4, 17], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4, 17,  5,\n",
       "         17,  5, 19,  4, 17,  5], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4, 17,  5, 17,\n",
       "          5, 19,  4, 17,  5, 14], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4, 17,  5, 17,  5,\n",
       "         19,  4, 17,  5, 14, 14], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4, 17,  5, 17,  5, 19,\n",
       "          4, 17,  5, 14, 14, 14], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4, 17,  5, 17,  5, 19,  4,\n",
       "         17,  5, 14, 14, 14, 14], device='cuda:0'),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  1, 10,  8,  8,  8,  6,  4,  4,  4, 17,  5, 17,  5, 19,  4, 17,\n",
       "          5, 14, 14, 14, 14, 14], device='cuda:0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner = EventGrouping(converter, model, neighborhood=1, seq_length=input_length)\n",
    "runner(components[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea085d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feature_keys = np.array([0,  2,  3,  4,  6,  7, 10, 14, 15, 16, 17, 18, 22, 24, 25, 26, 28, 29])\n",
    "dataset_training.__getitem__(0)[0][:, model_feature_keys][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1207fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.get(0).cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58b6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.node_feature_keys[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch_geometric.utils.to_networkx(dataset_test.get(0), to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5878291",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training.get(0).x[:, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2d2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "nx.draw(G, with_labels=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661d336",
   "metadata": {},
   "source": [
    "## Random Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ef8a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, feature_num, max_nodes, max_seq_length, dropout).to(device)\n",
    "weights = torch.load(\"/eos/user/c/czeh/tranformer_date_2025-05-30.pt\", weights_only=True)\n",
    "model.load_state_dict(weights[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580201de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114, 118, 125, 126, 127, 132, 134, 144, 149, 151, 152, 121, 145,\n",
       "       160, 120, 117, 191, 139, 142, 146])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components = dataset_test.get(0)\n",
    "components[0][\"lang\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a41c86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bde713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  1, 10], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nodes = components[0][\"nTrackster\"]\n",
    "converter = Lang(trackster_list=components[0][\"lang\"])\n",
    "sample_seq = converter.starting_seq(components[0][\"root\"], input_length).to(device)\n",
    "print(sample_seq)\n",
    "\n",
    "X = components[0][\"x\"].float()\n",
    "X = F.pad(X, pad=(0, 0, max_nodes - num_nodes, 0), value=converter.word2index[\"<PAD>\"])\n",
    "X = X[:, list(map(dataset_test.node_feature_dict.get, dataset_test.model_feature_keys))]\n",
    "\n",
    "predictions = model(torch.unsqueeze(X, dim=0), torch.unsqueeze(sample_seq, dim=0))\n",
    "torch.argsort(predictions[0, -1, :num_nodes], dim=0)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b73661",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[targets[:, -1] != -4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[mask].shape[0]/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774dde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = dataset_training.__getitem__(0)[1]\n",
    "opts = torch.roll(opts, -1, dims=0)\n",
    "opts[-1] = 5\n",
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ccda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask = opts != -4\n",
    "opts[out_mask].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c35fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.reshape(targets[mask], (int(targets[mask].shape[0]/3), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd836c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bf31c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

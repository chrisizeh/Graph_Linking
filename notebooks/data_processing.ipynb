{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3537c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST FOR TESTING PURPOSES, DATASET CREATION IN run_gnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d92c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.3.2.\n",
      "Python version\n",
      "3.11.10 | packaged by conda-forge | (main, Sep 30 2024, 18:08:57) [GCC 13.3.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=11, micro=10, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#print(sys.path)\n",
    "# sys.path.insert(0, '/eos/user/c/czeh/.local/lib/python3.9/site-packages')\n",
    "\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print(\"Python version\")\n",
    "print (sys.version)\n",
    "print(\"Version info.\")\n",
    "print (sys.version_info)\n",
    "\n",
    "input_folder = \"/eos/user/c/czeh/histo_10pion0PU\"\n",
    "output_folder = \"/eos/user/c/czeh/graph_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9421138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numpy version is 1.24.4.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "print('The numpy version is {}.'.format(np.__version__))\n",
    "\n",
    "import uproot as uproot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader.dataloader import DataLoader\n",
    "\n",
    "import joblib\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02984d93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tracksterLinker.datasets.ClusterDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtracksterLinker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClusterDataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClusterDataset\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtracksterLinker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphUtils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_ticl_graph\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtracksterLinker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataStatistics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_data_distribution\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tracksterLinker.datasets.ClusterDataset'"
     ]
    }
   ],
   "source": [
    "from tracksterLinker.datasets.ClusterDataset import ClusterDataset\n",
    "from tracksterLinker.utils.graphUtils import build_ticl_graph\n",
    "from tracksterLinker.utils.dataStatistics import plot_data_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cfc636",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e802d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to load the tree if some of file.keys() are duplicates ending with different numbers\n",
    "def load_branch_with_highest_cycle(file, branch_name):\n",
    "\n",
    "    # Get all keys in the file\n",
    "    all_keys = file.keys()\n",
    "\n",
    "    # Filter keys that match the specified branch name\n",
    "    matching_keys = [key for key in all_keys if key.startswith(branch_name)]\n",
    "\n",
    "    if not matching_keys:\n",
    "        raise ValueError(f\"No branch with name '{branch_name}' found in the file.\")\n",
    "\n",
    "    # Find the key with the highest cycle\n",
    "    highest_cycle_key = max(matching_keys, key=lambda key: int(key.split(\";\")[1]))\n",
    "\n",
    "    # Load the branch with the highest cycle\n",
    "    branch = file[highest_cycle_key]\n",
    "\n",
    "    return branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b0fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_folder = \"/eos/user/a/aperego/SampleProduction/TICLv5/ParticleGunPion/histo\"\n",
    "files = glob(f\"{input_folder}/train/*.root\")\n",
    "print(files[0])\n",
    "file = uproot.open(files[0])\n",
    "print(file.keys())\n",
    "\n",
    "alltracksters = load_branch_with_highest_cycle(file,'ticlDumper/ticlTrackstersCLUE3DHigh')\n",
    "allclusters = load_branch_with_highest_cycle(file,'ticlDumper/clusters')\n",
    "allsimtrackstersCP = load_branch_with_highest_cycle(file, 'ticlDumper/simtrackstersCP')\n",
    "allassociations = load_branch_with_highest_cycle(file, 'ticlDumper/associations')\n",
    "print(alltracksters.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alltracksters.arrays())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffeb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_keys_before = [\"barycenter_x\", \"barycenter_y\", \"barycenter_z\", \"barycenter_eta\", \"barycenter_phi\", \"eVector0_x\", \"eVector0_y\", \"eVector0_z\",  \"EV1\", \"EV2\", \"EV3\", \"sigmaPCA1\", \"sigmaPCA2\", \"sigmaPCA3\", \"raw_energy\", \"raw_em_energy\", \"time\"]\n",
    "data = alltracksters.arrays(node_feature_keys_before)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c1715",
   "metadata": {},
   "source": [
    "## Prepare Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltracksters_array = alltracksters.arrays()\n",
    "allassociations_array = allassociations.arrays()\n",
    "cluster_number_of_hits = allclusters.arrays().cluster_number_of_hits\n",
    "cluster_layer_id = allclusters.arrays().cluster_layer_id\n",
    "vertices_indexes = alltracksters.arrays().vertices_indexes\n",
    "NTracksters = alltracksters.arrays().NTracksters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    allgraph = self.load_branch_with_highest_cycle(file, 'ticlDumper/TICLGraph')\n",
    "    allgraph_array = allgraph.arrays()\n",
    "except:\n",
    "    allgraph = []\n",
    "    for i in range(len(NTracksters)):\n",
    "        allgraph.append(build_ticl_graph(NTracksters[i], alltracksters_array[i]))\n",
    "    allgraph_array = ak.Array(allgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9497ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vertices\"] = ak.concatenate([alltracksters_array[\"vertices_x\"][:, :, :, np.newaxis], alltracksters_array[\"vertices_y\"][:, :, :, np.newaxis], alltracksters_array[\"vertices_z\"][:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b39f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"vertices\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_LCs = ak.count(alltracksters.arrays().vertices_indexes, axis=2)\n",
    "data[\"num_LCs\"] = num_LCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22768147",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"z_min\"] = ak.min(alltracksters.arrays().vertices_z, axis=2)\n",
    "data[\"z_max\"] = ak.max(alltracksters.arrays().vertices_z, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee84ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = 2*(3 - 1.5) * (2 * 47)\n",
    "data[\"trackster_density\"] = ak.Array(np.zeros_like(data.num_LCs)) + NTracksters / volume\n",
    "data[\"LC_density\"] = data.num_LCs / volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e0fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hits = ak.to_list(np.zeros_like(data.num_LCs))\n",
    "length = ak.to_list(np.zeros_like(data.num_LCs))\n",
    "\n",
    "cluster_hits = cluster_number_of_hits[ak.flatten(vertices_indexes, axis=-1)]\n",
    "cluster_layer_ids = cluster_layer_id[ak.flatten(vertices_indexes, axis=-1)]\n",
    "vertices_count = ak.count(vertices_indexes, axis=-1)\n",
    "\n",
    "for i in range(len(alltracksters.arrays())):\n",
    "    hits[i] = ak.sum(ak.unflatten(cluster_hits[i], vertices_count[i]), axis=-1)\n",
    "    length[i] = (ak.max(ak.unflatten(cluster_layer_ids[i], vertices_count[i]), axis=-1) - ak.min(ak.unflatten(cluster_layer_ids[i], vertices_count[i]), axis=-1)) / 47\n",
    "        \n",
    "data[\"num_hits\"] = hits\n",
    "data[\"length\"] = length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e24929",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"photon_prob\"] = alltracksters.arrays()[\"id_probabilities\"][:, :, 0]\n",
    "data[\"electron_prob\"] = alltracksters.arrays()[\"id_probabilities\"][:, :, 1]\n",
    "data[\"muon_prob\"] = alltracksters.arrays()[\"id_probabilities\"][:, :, 2]\n",
    "data[\"neutral_pion_prob\"] = alltracksters.arrays()[\"id_probabilities\"][:, :, 3]\n",
    "data[\"charged_hadron_prob\"] = alltracksters.arrays()[\"id_probabilities\"][:, :, 4]\n",
    "data[\"neutral_hadron_prob\"] = alltracksters.arrays()[\"id_probabilities\"][:, :, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = allassociations_array.ticlTrackstersCLUE3DHigh_recoToSim_CP_score<0.2\n",
    "simTracksters = allassociations_array.ticlTrackstersCLUE3DHigh_recoToSim_CP[allassociations_array.ticlTrackstersCLUE3DHigh_recoToSim_CP_score<0.2]\n",
    "emptys = np.full_like(ak.count(allassociations_array.ticlTrackstersCLUE3DHigh_recoToSim_CP, axis=-1), -1) \n",
    "\n",
    "data[\"y\"] = ak.flatten(ak.where(ak.count(simTracksters, axis=-1)==1, allassociations_array.ticlTrackstersCLUE3DHigh_recoToSim_CP[idx], ak.unflatten(emptys, 1, axis=-1)), axis=-1)\n",
    "data[\"shared_e\"] = ak.flatten(ak.where(ak.count(simTracksters, axis=-1)==1, allassociations_array.ticlTrackstersCLUE3DHigh_recoToSim_CP_sharedE[idx], ak.unflatten(emptys, 1, axis=-1)), axis=-1)\n",
    "data[\"score\"] = ak.flatten(ak.where(ak.count(simTracksters, axis=-1)==1, allassociations_array.ticlTrackstersCLUE3DHigh_recoToSim_CP_score[idx], ak.unflatten(emptys, 1, axis=-1)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7247f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5aab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_keys = [\"barycenter_x\", \"barycenter_y\", \"barycenter_z\", \"barycenter_eta\", \"barycenter_phi\", \"eVector0_x\", \"eVector0_y\", \"eVector0_z\",  \"EV1\", \"EV2\", \"EV3\", \"sigmaPCA1\", \"sigmaPCA2\", \"sigmaPCA3\", \"num_LCs\", \"num_hits\", \"raw_energy\", \"raw_em_energy\", \"photon_prob\", \"electron_prob\", \"muon_prob\", \"neutral_pion_prob\", \"charged_hadron_prob\", \"neutral_hadron_prob\", \"z_min\", \"z_max\", \"length\", \"LC_density\", \"trackster_density\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e364fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_keys_plot = [\"barycenter_x\", \"barycenter_y\", \"barycenter_z\", \"y\", \"score\", \"shared_e\", \"barycenter_eta\", \"barycenter_phi\", \"eVector0_x\", \"eVector0_y\", \"eVector0_z\",  \"EV1\", \"EV2\", \"EV3\", \"sigmaPCA1\", \"sigmaPCA2\", \"sigmaPCA3\", \"num_LCs\", \"num_hits\", \"raw_energy\", \"raw_em_energy\", \"photon_prob\", \"electron_prob\", \"muon_prob\", \"neutral_pion_prob\", \"charged_hadron_prob\", \"neutral_hadron_prob\", \"z_min\", \"z_max\", \"length\", \"LC_density\", \"trackster_density\", \"time\"]\n",
    "node_feature_names_plot = [\"x\", \"y\", \"z\", \"sim_trackster\", \"sim_trackster_score\", \"sim_trackster_shared_energy\", \"eta\", \"phi\", \"eig_x\", \"eig_y\", \"eig_z\",  \"EV1\", \"EV2\", \"EV3\", \"sigmaPCA_x\", \"sigmaPCA_y\", \"sigmaPCA_z\", \"num_LC\", \"num_hits\", \"raw_energy\", \"raw_em_energy\", \"photon_prob\", \"electron_prob\", \"muon_prob\", \"neutral_pion_prob\", \"charged_hadron_prob\", \"neutral_hadron_prob\", \"z_min\", \"z_max\", \"length\", \"LC_density\", \"trackster_density\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_vals = []\n",
    "\n",
    "scols = int(np.ceil(len(node_feature_keys_plot)/2))\n",
    "srows = 2\n",
    "fig, axes = plt.subplots(scols, srows, figsize=(20, 35), constrained_layout=True)\n",
    "\n",
    "for i in tqdm(range(len(node_feature_keys_plot))):\n",
    "    ax_col = int(i%scols)\n",
    "    ax_row = int(i/scols)\n",
    "    \n",
    "    values = ak.flatten(data[node_feature_keys_plot[i]])\n",
    "    track_vals.append(values)\n",
    "    sns.histplot(values, ax=axes[ax_col, ax_row], kde=True, stat=\"density\", linewidth=0, bins=15)\n",
    "    axes[ax_col, ax_row].set_title('Frequency distribution '+ node_feature_names_plot[i], fontsize=18)\n",
    "    axes[ax_col, ax_row].set_xlabel(node_feature_names_plot[i], fontsize=15)\n",
    "    axes[ax_col, ax_row].set_ylabel('Count', fontsize=15)\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_vals = np.array(track_vals)\n",
    "track_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbe312",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = np.corrcoef(track_vals)\n",
    "print(corr_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c49397",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 10))\n",
    "plt.matshow(corr_matrix, fignum=f.number, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "\n",
    "plt.xticks(range(len(node_feature_names_plot)), node_feature_names_plot, fontsize=14, rotation=-45, ha=\"left\")\n",
    "plt.yticks(range(len(node_feature_names_plot)), node_feature_names_plot, fontsize=14)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "cb = plt.colorbar(shrink=0.5)\n",
    "cb.ax.tick_params(labelsize=14)\n",
    "plt.title('Correlation Matrix of the Trackster Features', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e05c23",
   "metadata": {},
   "source": [
    "## Check no PileUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa77be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(data[0].barycenter_x, data[0].barycenter_y, data[0].barycenter_z)\n",
    "\n",
    "ax.set_xlabel('x (cm)')\n",
    "ax.set_ylabel('y (cm)')\n",
    "ax.set_zlabel('z (cm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0751351d",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86322237",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_dict = {k: v for v, k in enumerate(node_feature_keys)}\n",
    "standard_norm_keys = [\"barycenter_x\", \"barycenter_y\", \"barycenter_z\", \"barycenter_eta\", \"barycenter_phi\", \"eVector0_x\", \"eVector0_y\", \"eVector0_z\", \"EV1\", \"EV2\", \"EV3\",\n",
    "                         \"sigmaPCA1\", \"sigmaPCA2\", \"sigmaPCA3\", \"num_LCs\", \"num_hits\", \"raw_energy\", \"raw_em_energy\", \"photon_prob\", \"electron_prob\", \"muon_prob\",\n",
    "                         \"neutral_pion_prob\", \"charged_hadron_prob\", \"neutral_hadron_prob\", \"z_min\", \"z_max\", \"LC_density\", \"trackster_density\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b09ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1\n",
    "for event in range(10):    \n",
    "    nodes = np.zeros((NTracksters[event], len(node_feature_keys)))\n",
    "    for i, key in enumerate(node_feature_keys):\n",
    "        nodes[:, i] = ak.to_numpy(data[event][key])            \n",
    "    \n",
    "    if start == 1:\n",
    "        X = pd.DataFrame(nodes, columns=node_feature_keys)\n",
    "        start = 0\n",
    "    else:\n",
    "        Y = pd.DataFrame(nodes, columns=node_feature_keys)\n",
    "        X = pd.concat([X, Y], ignore_index=True)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(X)\n",
    "joblib.dump(scaler, \"/eos/user/c/czeh/graph_data/scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e826aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X/scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcef1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler.transform(X), columns=node_feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_scaler = joblib.load(\"/eos/user/c/czeh/graph_data/scaler.joblib\")\n",
    "X_mm = pd.DataFrame(loaded_scaler.transform(X), columns=node_feature_keys)\n",
    "plot_data_distribution(X_mm, node_feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ad0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_X = X[[\"barycenter_eta\", \"barycenter_phi\", \"raw_energy\"]]\n",
    "filtered_tensor = torch.unsqueeze(torch.tensor(X.to_numpy()), dim=0)\n",
    "filtered_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b288c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tensor = F.pad(filtered_tensor, pad=(0, 0, 5, 0), value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tensor[torch.sum(filtered_tensor, dim=2) != 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mask = (torch.sum(filtered_tensor, dim=2) != 0).unsqueeze(1).unsqueeze(2)\n",
    "src_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5719b6",
   "metadata": {},
   "source": [
    "## Create Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7bf7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = ak.num(allgraph_array.inner, axis=-1)\n",
    "data[\"roots\"] = ak.local_index(roots)[roots  == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22851d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"idx\"] = ak.local_index(data.barycenter_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d99bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list = []\n",
    "for event in range(10):    \n",
    "    nodes = np.zeros((NTracksters[event], len(node_feature_keys)))\n",
    "    for i, key in enumerate(node_feature_keys):\n",
    "        nodes[:, i] = ak.to_numpy(data[event][key])\n",
    "\n",
    "    # Create base graph from geometrical graph    \n",
    "    edges = [[], []]\n",
    "    for i in range(NTracksters[event]):\n",
    "        edges[0].extend([i] * len(allgraph_array[event].outer[i]))    \n",
    "        edges[1].extend(allgraph_array[event].outer[i])\n",
    "        \n",
    "    edges = np.array(edges)\n",
    "    \n",
    "    edge_features = np.zeros((len(edges[0, :]), 7))\n",
    "    edge_features[:, 4] = np.linalg.norm(nodes[edges[1, :], :2] - nodes[edges[0, :], :2], axis=1)\n",
    "    \n",
    "    edge_features[:, 0] = np.abs(nodes[edges[1, :], 16] - nodes[edges[0, :], 16])\n",
    "    edge_features[:, 1] = np.abs(nodes[edges[1, :], 2] - nodes[edges[0, :], 2])\n",
    "    edge_features[:, 5] = np.arccos(np.clip(np.sum(np.multiply(nodes[edges[1, :], 5:8], nodes[edges[0, :], 5:8]), axis=1), a_min=-1, a_max=1))\n",
    "    edge_features[:, 6] = np.abs(nodes[edges[1, :], 28] - nodes[edges[0], 28])\n",
    "    \n",
    "    # y\n",
    "    y = np.zeros(edges.shape[1])\n",
    "    for i, e in enumerate(edges.T):\n",
    "        if((data[event].y[e[0]] != -1) and (data[event].y[e[0]] == data[event].y[e[1]])):\n",
    "            y[i] = (1-data[event].score[e[0]]) * data[event].shared_e[e[0]]/data[event].raw_energy[e[0]] + (1-data[event].score[e[1]]) * data[event].shared_e[e[1]]/data[event].raw_energy[e[1]]\n",
    "            \n",
    "    graph_list.append(Data(x=torch.from_numpy(nodes), num_nodes=NTracksters[event],\n",
    "                        edge_index=torch.from_numpy(edges), edges_features=edge_features, y=torch.from_numpy(y),\n",
    "                          y_trans = data[\"y\"][event]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbf78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f89ec7",
   "metadata": {},
   "source": [
    "## Prepare Slow Edge Data\n",
    "Not in Graph Data, as way to slow just for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transp = edges.T\n",
    "edge_indices = np.zeros((NTracksters[event], NTracksters[event], ), dtype=np.int64)\n",
    "\n",
    "for i in range(len(edges[0, :])):\n",
    "    edge_indices[transp[i, 0], transp[i, 1]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root in range(edge_indices.shape[0]):\n",
    "    tree = KDTree(data[\"vertices\"][0, root], leaf_size=2)\n",
    "    num = len(data[\"vertices\"][0, root])\n",
    "    for target in range(edge_indices.shape[1]):\n",
    "        if (edge_indices[root, target] == -1):\n",
    "            continue\n",
    "        if (root != target):\n",
    "            dist, _ = tree.query(data[\"vertices\"][0, target], k=num)\n",
    "            edge_features[edge_indices[root, target], 2] = np.min(dist)\n",
    "            edge_features[edge_indices[root, target], 3] = np.max(dist)\n",
    "\n",
    "            edge_features[edge_indices[target, root], 2] = np.min(dist)\n",
    "            edge_features[edge_indices[target, root], 3] = np.max(dist)\n",
    "        else:\n",
    "            edge_features[edge_indices[root, target], 2] = 0\n",
    "            edge_features[edge_indices[root, target], 3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bedf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(edge_features[:, 4]))\n",
    "print(np.median(edge_features[:, 4]))\n",
    "print(np.min(edge_features[:, 4]))\n",
    "print(np.max(edge_features[:, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f0429",
   "metadata": {},
   "source": [
    "## Analyse Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "hist_folder = \"/eos/user/c/czeh/histo/\"\n",
    "data_folder_training = \"/eos/user/c/czeh/graph_data\"\n",
    "data_folder_test = \"/eos/user/c/czeh/graph_data_test\"\n",
    "\n",
    "model_folder = \"/eos/user/c/czeh/model\"\n",
    "dataset_training = ClusterDataset(data_folder_training, hist_folder)\n",
    "dataset_test = ClusterDataset(data_folder_test, hist_folder, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba61ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(dataset_training, shuffle=True)\n",
    "test_dl = DataLoader(dataset_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cfbada",
   "metadata": {},
   "source": [
    "### Distribution of Score value -> How many Edges 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ac260",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = {}\n",
    "\n",
    "for sample in test_dl:\n",
    "    unique, counts = np.unique(sample.y, return_counts=True)\n",
    "    \n",
    "    for i, val in enumerate(unique):\n",
    "        if val in val_counts:\n",
    "            val_counts[val] += counts[i]\n",
    "        else:\n",
    "            val_counts[val] = counts[i]\n",
    "val_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6ef95",
   "metadata": {},
   "source": [
    "## Analyze Subgraph building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e28a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lang import Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018ca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nodes = 255\n",
    "input_length = 20\n",
    "converter = Lang(max_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.word2index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c780465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_subgraph(graph, root, neighborhood=1):\n",
    "        neighbors = graph[1][graph[0] == root]\n",
    "        neighbors = torch.cat((neighbors, graph[0][graph[1] == root]))\n",
    "\n",
    "        if (neighborhood == 0):\n",
    "            return neighbors\n",
    "        subgraph = np.copy(neighbors)\n",
    "\n",
    "        for n in neighbors:\n",
    "            subgraph = np.append(subgraph, build_subgraph(graph, n, neighborhood-1))\n",
    "\n",
    "        return np.unique(subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0efb252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = 14\n",
    "X = dataset_training.get(data_idx)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dea898",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch_geometric.utils.to_networkx(X, to_undirected=True)\n",
    "newData = Data(x=X.x, num_nodes=X.num_nodes, edge_index=X.edge_index[:, X.y > 0])\n",
    "newG = torch_geometric.utils.to_networkx(newData, to_undirected=True)\n",
    "\n",
    "pos = dict(zip(list(range(X.num_nodes)), X.x[:, :2]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "nx.draw(G, with_labels=True, ax=ax[0], pos=pos, node_size=X.x[:, 16]*5)\n",
    "nx.draw(newG, with_labels=True, ax=ax[1], pos=pos, node_size=X.x[:, 16]*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c59ff92",
   "metadata": {},
   "source": [
    "Cycle trough a full sequence creation by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee519d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = X.roots[np.argsort(-X.x[X.roots, 16])]\n",
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = roots[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4858214",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_subgraph = np.array(build_subgraph(X.edge_index, root, 1), dtype=int)\n",
    "root_subgraph = root_subgraph[np.argsort(-X.x[root_subgraph, 16])]\n",
    "root_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d722ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_graph = np.array(np.argsort(-X.x[:, 16]), dtype=int)\n",
    "sorted_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fed2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (root_subgraph.shape[0] > 1):\n",
    "    root_group = sorted_graph[X.cluster[sorted_graph] == X.cluster[root].item()]\n",
    "else:\n",
    "    root_group = sorted_graph\n",
    "root_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_seq = converter.y2seq(root, sorted_graph, np.array(X.cluster))\n",
    "sample_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "visited = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb09afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = sample_seq.shape[0]-3\n",
    "seq = converter.subseq(sample_seq, seq_length=input_length, index=i-input_length+2)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph = np.array([])\n",
    "if (seq[-1] > converter.word2index[\";\"]):\n",
    "    new_root = int(converter.index2word[seq[-1]])\n",
    "    subgraph = np.array(build_subgraph(X.edge_index, new_root, 2), dtype=int)\n",
    "    subgraph = np.array(subgraph, dtype=int)\n",
    "    \n",
    "    subgraph = np.setdiff1d(subgraph, np.array(visited))\n",
    "    visited.append(seq[-1])\n",
    "subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be2446",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (subgraph.shape[0] > 1):\n",
    "    group = subgraph[X.cluster[subgraph] == X.cluster[new_root].item()]\n",
    "    group = np.setdiff1d(group, visited)\n",
    "    \n",
    "    if (group.shape[0] == 0):\n",
    "        group = sample_seq[i+2]\n",
    "elif(subgraph.shape[0] == 1):\n",
    "    group = subgraph\n",
    "else:\n",
    "    group = sample_seq[i+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbac6bb",
   "metadata": {},
   "source": [
    "## Graph Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ClusterDataset import ClusterDataset\n",
    "from graph_utils import find_connected_components\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_training = \"/eos/user/c/czeh/graph_data\"\n",
    "hist_folder = \"/eos/user/c/czeh/histo/\"\n",
    "dataset_training = ClusterDataset(data_folder_training, hist_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_idx = 0\n",
    "X = dataset_training.get(data_idx)\n",
    "print(X.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d337c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "nodes = []\n",
    "roots = []\n",
    "\n",
    "components = find_connected_components(X.edge_index, X.x.shape[0])\n",
    "\n",
    "for component in components:\n",
    "    component = np.array(component, dtype=int)\n",
    "    if (component.shape[0] <= 1):\n",
    "        continue\n",
    "    \n",
    "    root = torch.argmax(X.x[component, 16]).item()\n",
    "    root_cluster = X.cluster[root].item()\n",
    "    sample_seq = converter.y2seq(root, component, np.array(X.cluster))   \n",
    "    print(sample_seq)\n",
    "    seq = np.array(list(map(converter.index2word.get, sample_seq)))[1:-2]\n",
    "\n",
    "    node = []\n",
    "    print(seq)\n",
    "    roots.append(int(seq[0]))\n",
    "    for i in range(seq.shape[0]):\n",
    "        if(seq[i] == \";\"):\n",
    "            nodes.append(node)\n",
    "            node = []\n",
    "        else:\n",
    "            node.append(int(seq[i]))\n",
    "        \n",
    "        if (i+1 < seq.shape[0] and seq[i] != \";\" and seq[i + 1] != \";\"):\n",
    "            edges.append([int(seq[i]), int(seq[i+1])])\n",
    "edges = np.array(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8daa1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf11651",
   "metadata": {},
   "outputs": [],
   "source": [
    "s='''\n",
    "        aliceblue, antiquewhite, aqua, aquamarine, azure,\n",
    "        beige, bisque, black, blanchedalmond, blue,\n",
    "        blueviolet, brown, burlywood, cadetblue,\n",
    "        chartreuse, chocolate, coral, cornflowerblue,\n",
    "        cornsilk, crimson, cyan, darkblue, darkcyan,\n",
    "        darkgoldenrod, darkgray, darkgrey, darkgreen,\n",
    "        darkkhaki, darkmagenta, darkolivegreen, darkorange,\n",
    "        darkorchid, darkred, darksalmon, darkseagreen,\n",
    "        darkslateblue, darkslategray, darkslategrey,\n",
    "        darkturquoise, darkviolet, deeppink, deepskyblue,\n",
    "        dimgray, dimgrey, dodgerblue, firebrick,\n",
    "        floralwhite, forestgreen, fuchsia, gainsboro,\n",
    "        ghostwhite, gold, goldenrod, gray, grey, green,\n",
    "        greenyellow, honeydew, hotpink, indianred, indigo,\n",
    "        ivory, khaki, lavender, lavenderblush, lawngreen,\n",
    "        lemonchiffon, lightblue, lightcoral, lightcyan,\n",
    "        lightgoldenrodyellow, lightgray, lightgrey,\n",
    "        lightgreen, lightpink, lightsalmon, lightseagreen,\n",
    "        lightskyblue, lightslategray, lightslategrey,\n",
    "        lightsteelblue, lightyellow, lime, limegreen,\n",
    "        linen, magenta, maroon, mediumaquamarine,\n",
    "        mediumblue, mediumorchid, mediumpurple,\n",
    "        mediumseagreen, mediumslateblue, mediumspringgreen,\n",
    "        mediumturquoise, mediumvioletred, midnightblue,\n",
    "        mintcream, mistyrose, moccasin, navajowhite, navy,\n",
    "        oldlace, olive, olivedrab, orange, orangered,\n",
    "        orchid, palegoldenrod, palegreen, paleturquoise,\n",
    "        palevioletred, papayawhip, peachpuff, peru, pink,\n",
    "        plum, powderblue, purple, red, rosybrown,\n",
    "        royalblue, saddlebrown, salmon, sandybrown,\n",
    "        seagreen, seashell, sienna, silver, skyblue,\n",
    "        slateblue, slategray, slategrey, snow, springgreen,\n",
    "        steelblue, tan, teal, thistle, tomato, turquoise,\n",
    "        violet, wheat, white, whitesmoke, yellow,\n",
    "        yellowgreen\n",
    "        '''\n",
    "li=s.split(',')\n",
    "li=[l.replace('\\n','') for l in li]\n",
    "color=[l.replace(' ','') for l in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee86886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Extract edge coordinates\n",
    "edge_x, edge_y, edge_z = [], [], []\n",
    "for u, v in edges:\n",
    "    x0, y0, z0 = X.x[u, :3]\n",
    "    x1, y1, z1 = X.x[v, :3]\n",
    "    edge_x += [x0, x1, None]\n",
    "    edge_y += [y0, y1, None]\n",
    "    edge_z += [z0, z1, None]\n",
    "\n",
    "\n",
    "# Add edges\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=edge_x, y=edge_y, z=edge_z,\n",
    "    mode='lines',\n",
    "    line=dict(color='gray', width=2),\n",
    "    hoverinfo='none'\n",
    "))\n",
    "\n",
    "# Node coordinates\n",
    "for c in torch.unique(X.cluster):\n",
    "    node_x = [node[0].item() for node in X.x[X.cluster == c.item()]]\n",
    "    node_y = [node[1].item() for node in X.x[X.cluster == c.item()]]\n",
    "    node_z = [node[2].item() for node in X.x[X.cluster == c.item()]]\n",
    "    node_size = [node[16].item()/2 for node in X.x[X.cluster == c.item()]]\n",
    "    name = np.array(range(X.x.shape[0]))[X.cluster == c.item()]\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=node_x, y=node_y, z=node_z,\n",
    "        mode='markers',\n",
    "        marker=dict(size=node_size, color=color[c.item()]),\n",
    "        hoverinfo='text',\n",
    "        text=[str(i) for i in range(X.x.shape[0])]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Sequence Line of two Trackster Group; Event: {data_idx}',\n",
    "    showlegend=False,\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=False),\n",
    "        yaxis=dict(showgrid=False),\n",
    "        zaxis=dict(showgrid=False)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "x = edges.T[0]\n",
    "y = edges.T[1]\n",
    "sizes = [100, 200, 300, 400, 500]  # size for each point\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for c in torch.unique(X.cluster):\n",
    "    node_x = [node[3].item() for node in X.x[X.cluster == c.item()]]\n",
    "    node_y = [node[4].item() for node in X.x[X.cluster == c.item()]]\n",
    "    node_size = [node[16].item()*2 for node in X.x[X.cluster == c.item()]]\n",
    "    name = np.array(range(X.x.shape[0]))[X.cluster == c.item()]\n",
    "    plt.scatter(node_x, node_y, s=node_size, c=color[c.item()], alpha=0.6, label='Points')\n",
    "\n",
    "for node in nodes:\n",
    "    # Connect points with lines\n",
    "    endpoints = X.x[node]\n",
    "    plt.plot(endpoints[:, 3], endpoints[:, 4], color='gray', linestyle='-', linewidth=1, label='Connections')\n",
    "    \n",
    "root_points = X.x[roots]\n",
    "plt.scatter(root_points[:, 3], root_points[:, 4], s=root_points[:, 16], color='green', label='Root')\n",
    "\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('eta')\n",
    "plt.ylabel('phi')\n",
    "plt.title(f'Sequence Line of two Trackster Group; Event: {data_idx}')\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde91b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
